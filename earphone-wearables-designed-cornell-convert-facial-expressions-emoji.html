<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Earphone wearables designed at Cornell convert facial expressions into emoji with nearly 90 per cent -</title><meta name=robots content="index,follow,noarchive"><meta name=description content="The perfect emoji speaks louder than words, but finding the right one among the more than 3,000 that exist can be difficult. Now a group of researchers discovered a new way to help people find the emoji that best matches their facial expressions, no typing or talking required. And it could have applications beyond just expressive texting.
The invention, created by a team from Cornell University, involves an earphone or headphone system called C-Face."><meta name=author content="Martina Birk"><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/app.css><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/an-old-hope.min.css><script defer src=https://assets.cdnweb.info/hugo/paper/js/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=./theme.png><link rel=icon href=./favicon.ico><link rel=apple-touch-icon href=./apple-touch-icon.png><meta name=generator content="Hugo 0.98.0"><meta property="og:title" content="Earphone wearables designed at Cornell convert facial expressions into emoji with nearly 90 per cent"><meta property="og:description" content="The perfect emoji speaks louder than words, but finding the right one among the more than 3,000 that exist can be difficult. Now a group of researchers discovered a new way to help people find the emoji that best matches their facial expressions, no typing or talking required. And it could have applications beyond just"><meta property="og:type" content="article"><meta property="og:url" content="/earphone-wearables-designed-cornell-convert-facial-expressions-emoji.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-04-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-04-29T00:00:00+00:00"><meta itemprop=name content="Earphone wearables designed at Cornell convert facial expressions into emoji with nearly 90 per cent"><meta itemprop=description content="The perfect emoji speaks louder than words, but finding the right one among the more than 3,000 that exist can be difficult. Now a group of researchers discovered a new way to help people find the emoji that best matches their facial expressions, no typing or talking required. And it could have applications beyond just"><meta itemprop=datePublished content="2024-04-29T00:00:00+00:00"><meta itemprop=dateModified content="2024-04-29T00:00:00+00:00"><meta itemprop=wordCount content="549"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Earphone wearables designed at Cornell convert facial expressions into emoji with nearly 90 per cent"><meta name=twitter:description content="The perfect emoji speaks louder than words, but finding the right one among the more than 3,000 that exist can be difficult. Now a group of researchers discovered a new way to help people find the emoji that best matches their facial expressions, no typing or talking required. And it could have applications beyond just"></head><body class=not-ready data-menu=true><header class=header><p class=logo><a class=site-name href=./index.html>ZenVlog</a><a class=btn-dark></a></p><script>let bodyClx=document.body.classList,btnDark=document.querySelector(".btn-dark"),sysDark=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark"),setDark=e=>{bodyClx[e?"add":"remove"]("dark"),localStorage.setItem("dark",e?"yes":"no")};setDark(darkVal?darkVal==="yes":sysDark.matches),requestAnimationFrame(()=>bodyClx.remove("not-ready")),btnDark.addEventListener("click",()=>setDark(!bodyClx.contains("dark"))),sysDark.addEventListener("change",e=>setDark(e.matches))</script><nav class=menu><a href=./sitemap.xml>Sitemap</a></nav></header><main class=main><article class=post-single><header class=post-title><p><time>Apr 29, 2024</time>
<span>Martina Birk</span></p><h1>Earphone wearables designed at Cornell convert facial expressions into emoji with nearly 90 per cent</h1></header><section class=post-content><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">The perfect emoji speaks louder than words, but finding the right one among the more than 3,000 that exist can be difficult. Now a group of researchers discovered a new way to help people find the emoji that best matches their facial expressions, no typing or talking required. And it could have applications beyond just expressive texting.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">The invention, created by a team from Cornell University, involves an earphone or headphone system called C-Face. Cameras are attached to each earpiece, recording changes in the contours of the wearer’s face as it moves. The data is processed using deep learning, a branch of AI in which algorithms learn tasks by looking for patterns within a massive amount of data.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Most of the facial changes were found to occur in the mouth, eyes and eyebrows. By following these feature points, researchers said their system was able to reconstruct facial expressions such as a smile, grimace, sneer or frown. It works even for people wearing glasses or medical masks because the contour of the face remains visible.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">In the study, participants were also asked to make facial expressions corresponding to some common emoji like “kissy-face” and “sneer”. Based on their faces, the AI-trained system successfully found the right emoji more than 88 per cent of the time.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Researchers said that in the real world, C-Face could allow users to insert an emoji in a message just by imitating it with their face. Since the system tracks the facial expression with the earphones, smartphone users could look away from their screen and continue with other tasks, whether it is jogging or doing the dishes. The small size of the earphones could make them ideal mobile wearables.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">“This device is simpler, less obtrusive and more capable than any existing ear-mounted wearable technologies for tracking facial expressions,” said Cheng Zhang, senior author of the research paper and director of Cornell’s SciFi Lab. “In previous wearable technology aiming to recognise facial expressions, most solutions needed to attach sensors on the face.”</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Another potential application is silent speech recognition. Participants in the study were asked to mouth several commands to control a music player, such as “play”, “stop” and “next song”. The accuracy was nearly 85 per cent. Researchers suggested that this could be useful not just for the disabled, but also in noisy environments or settings where it is inappropriate to speak.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/cdn.i-scmp.com/sites/default/files/d8/images/methode/2020/10/13/839a5808-0d28-11eb-94e0-02af7fd927c6_972x_164612.jpg><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">There might also be opportunities in virtual and augmented reality. Whereas traditional VR/AR headsets only allow the wearers to show each other what they see, C-Face can also let people see each other’s facial expressions, said study co-author Francois Guimbretière.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">Despite the encouraging initial findings, the Cornell team said they only conducted the study indoors with nine participants because of Covid-19 restrictions. More research is needed to find out how the system might work in different environments. And a larger data set from more participants will also help the system improve its performance.</p><p datatype="p" data-qa=Component-Component class="e15kmbpe0 css-1c6uqr6 e1346ty31">However, C-Face currently has one pitfall: limited battery life. In the study, researchers connected the earphone cameras to several Raspberry Pi boards which consumed “a relatively high amount of power”, researchers said. Raspberry Pi is a small computer built on a single circuit board. Using a less energy-consuming alternative could save nearly 90 per cent of the power, they said.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7tK%2FMqWWcp51krqOtwq6qaKyVmLVwrdGtoJyklWSAcnyUbGlrZ5WWv7G0zqecZq%2BVlr%2Birsueqmaclai2qLrEnWScp6Kjsq24jJymp66Vp8FussCcoJqkXZrFsb7ErKqip56oeqa5zqOg</p></section><nav class=post-nav><a class=prev href=./15-facts-about-hay-on-wye-literature-festival.html><span>←</span><span>15 Facts About Hay-on-Wye Literature Festival</span></a>
<a class=next href=./keith-richards-and-linda-keith.html><span>Keith Richards and Linda Keith</span><span>→</span></a></nav></article></main><footer class=footer><p>&copy; 2024 <a href=./></a></p><p>Powered by <a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>️</p></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>